{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Question 1:\n",
    "\n",
    "Please use the grutenberg corpus provided in nltk and extract the text written by Lewis Caroll, i.e., fileid == 'carroll-alice.txt', as your corpus data.\n",
    "\n",
    "With this corpus data, please perform text preprocessing on the sentences of the corpus.\n",
    "\n",
    "In particular, please:\n",
    "    - pos-tag all the sentences to get the parts-of-speech of each word\n",
    "    - lemmatize all words using WordNetLemmatizer in NLTK on a sentential basis\n",
    "\n",
    "Please provide your output as shown below:\n",
    "    - it is a data frame\n",
    "    - the column alice_sents includes the original sentence texts\n",
    "    - the column alice_sents_pos includes annotated version of the sentences with each token as word/postag\n",
    "    - the column sents_lem includes the lemmatized version of the sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /Users/linkuanyu/opt/anaconda3/lib/python3.7/site-packages (3.5)\n",
      "Requirement already satisfied: regex in /Users/linkuanyu/opt/anaconda3/lib/python3.7/site-packages (from nltk) (2021.3.17)\n",
      "Requirement already satisfied: tqdm in /Users/linkuanyu/opt/anaconda3/lib/python3.7/site-packages (from nltk) (4.59.0)\n",
      "Requirement already satisfied: joblib in /Users/linkuanyu/opt/anaconda3/lib/python3.7/site-packages (from nltk) (1.0.1)\n",
      "Requirement already satisfied: click in /Users/linkuanyu/opt/anaconda3/lib/python3.7/site-packages (from nltk) (7.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Users/linkuanyu/opt/anaconda3/lib/python3.7/site-packages (1.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Users/linkuanyu/opt/anaconda3/lib/python3.7/site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Users/linkuanyu/opt/anaconda3/lib/python3.7/site-packages (from pandas) (2021.1)\n",
      "Requirement already satisfied: numpy>=1.16.5 in /Users/linkuanyu/opt/anaconda3/lib/python3.7/site-packages (from pandas) (1.20.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/linkuanyu/opt/anaconda3/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import gutenberg\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package gutenberg to\n",
      "[nltk_data]     /Users/linkuanyu/nltk_data...\n",
      "[nltk_data]   Package gutenberg is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('gutenberg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "alice =  nltk.corpus.gutenberg.sents('carroll-alice.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/linkuanyu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"[ Alice ' s Adventures in Wonderland by Lewis Carroll 1865 ]\", 'CHAPTER I .', 'Down the Rabbit - Hole']\n"
     ]
    }
   ],
   "source": [
    "sents = [' '.join(s) for s in alice]\n",
    "print(sents[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/linkuanyu/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('[', 'JJ'), ('Alice', 'NNP'), (\"'\", 'POS'), ('s', 'NN'), ('Adventures', 'NNS'), ('in', 'IN'), ('Wonderland', 'NNP'), ('by', 'IN'), ('Lewis', 'NNP'), ('Carroll', 'NNP'), ('1865', 'CD'), (']', 'NN')], [('CHAPTER', 'NN'), ('I', 'PRP'), ('.', '.')], [('Down', 'IN'), ('the', 'DT'), ('Rabbit', 'NNP'), ('-', ':'), ('Hole', 'NN')]]\n"
     ]
    }
   ],
   "source": [
    "text_pos = [pos_tag(s) for s in alice]\n",
    "print(text_pos[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"[/JJ Alice/NNP '/POS s/NN Adventures/NNS in/IN Wonderland/NNP by/IN Lewis/NNP Carroll/NNP 1865/CD ]/NN\", 'CHAPTER/NN I/PRP ./.', 'Down/IN the/DT Rabbit/NNP -/: Hole/NN']\n"
     ]
    }
   ],
   "source": [
    "sents_pos = [' '.join(['/'.join(pair) for pair in s]) for s in text_pos]\n",
    "print(sents_pos[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n"
     ]
    }
   ],
   "source": [
    "def get_wordnet_pos(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "print(get_wordnet_pos('JJ'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"[ Alice ' s Adventures in Wonderland by Lewis Carroll 1865 ]\", 'CHAPTER I .', 'Down the Rabbit - Hole', \"Alice be begin to get very tired of sit by her sister on the bank , and of have nothing to do : once or twice she have peep into the book her sister be read , but it have no picture or conversation in it , ' and what be the use of a book ,' think Alice ' without picture or conversation ?'\"]\n"
     ]
    }
   ],
   "source": [
    "wnl = WordNetLemmatizer()\n",
    "sents_lem = [' '.join([wnl.lemmatize(pair[0], pos = get_wordnet_pos(pair[1])) for pair in s]) for s in text_pos]\n",
    "print(sents_lem[:4])\n",
    "#wnl.lemmatize('ate', v) --> eat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sents</th>\n",
       "      <th>Sents_pos</th>\n",
       "      <th>Sents_lem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[ Alice ' s Adventures in Wonderland by Lewis ...</td>\n",
       "      <td>[/JJ Alice/NNP '/POS s/NN Adventures/NNS in/IN...</td>\n",
       "      <td>[ Alice ' s Adventures in Wonderland by Lewis ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CHAPTER I .</td>\n",
       "      <td>CHAPTER/NN I/PRP ./.</td>\n",
       "      <td>CHAPTER I .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Down the Rabbit - Hole</td>\n",
       "      <td>Down/IN the/DT Rabbit/NNP -/: Hole/NN</td>\n",
       "      <td>Down the Rabbit - Hole</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alice was beginning to get very tired of sitti...</td>\n",
       "      <td>Alice/NNP was/VBD beginning/VBG to/TO get/VB v...</td>\n",
       "      <td>Alice be begin to get very tired of sit by her...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>So she was considering in her own mind ( as we...</td>\n",
       "      <td>So/IN she/PRP was/VBD considering/VBG in/IN he...</td>\n",
       "      <td>So she be consider in her own mind ( as well a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>There was nothing so VERY remarkable in that ;...</td>\n",
       "      <td>There/EX was/VBD nothing/NN so/RB VERY/RB rema...</td>\n",
       "      <td>There be nothing so VERY remarkable in that ; ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Oh dear !</td>\n",
       "      <td>Oh/UH dear/NN !/.</td>\n",
       "      <td>Oh dear !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>I shall be late !'</td>\n",
       "      <td>I/PRP shall/MD be/VB late/JJ !'/NN</td>\n",
       "      <td>I shall be late !'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>( when she thought it over afterwards , it occ...</td>\n",
       "      <td>(/( when/WRB she/PRP thought/VBD it/PRP over/I...</td>\n",
       "      <td>( when she think it over afterwards , it occur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>In another moment down went Alice after it , n...</td>\n",
       "      <td>In/IN another/DT moment/NN down/RP went/VBD Al...</td>\n",
       "      <td>In another moment down go Alice after it , nev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>The rabbit - hole went straight on like a tunn...</td>\n",
       "      <td>The/DT rabbit/NN -/: hole/NN went/VBD straight...</td>\n",
       "      <td>The rabbit - hole go straight on like a tunnel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Either the well was very deep , or she fell ve...</td>\n",
       "      <td>Either/CC the/DT well/NN was/VBD very/RB deep/...</td>\n",
       "      <td>Either the well be very deep , or she fell ver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>First , she tried to look down and make out wh...</td>\n",
       "      <td>First/RB ,/, she/PRP tried/VBD to/TO look/VB d...</td>\n",
       "      <td>First , she try to look down and make out what...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>She took down a jar from one of the shelves as...</td>\n",
       "      <td>She/PRP took/VBD down/RP a/DT jar/NN from/IN o...</td>\n",
       "      <td>She take down a jar from one of the shelf a sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>' Well !'</td>\n",
       "      <td>'/POS Well/NNP !'/NN</td>\n",
       "      <td>' Well !'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>thought Alice to herself , ' after such a fall...</td>\n",
       "      <td>thought/VBN Alice/NNP to/TO herself/VB ,/, '/'...</td>\n",
       "      <td>think Alice to herself , ' after such a fall a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>How brave they ' ll all think me at home !</td>\n",
       "      <td>How/WRB brave/VBP they/PRP '/'' ll/VBP all/DT ...</td>\n",
       "      <td>How brave they ' ll all think me at home !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Why , I wouldn ' t say anything about it , eve...</td>\n",
       "      <td>Why/WRB ,/, I/PRP wouldn/VBP '/'' t/NNS say/VB...</td>\n",
       "      <td>Why , I wouldn ' t say anything about it , eve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>( Which was very likely true .)</td>\n",
       "      <td>(/( Which/NNP was/VBD very/RB likely/JJ true/J...</td>\n",
       "      <td>( Which be very likely true .)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Down , down , down .</td>\n",
       "      <td>Down/NNP ,/, down/RB ,/, down/RB ./.</td>\n",
       "      <td>Down , down , down .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Sents  \\\n",
       "0   [ Alice ' s Adventures in Wonderland by Lewis ...   \n",
       "1                                         CHAPTER I .   \n",
       "2                              Down the Rabbit - Hole   \n",
       "3   Alice was beginning to get very tired of sitti...   \n",
       "4   So she was considering in her own mind ( as we...   \n",
       "5   There was nothing so VERY remarkable in that ;...   \n",
       "6                                           Oh dear !   \n",
       "7                                  I shall be late !'   \n",
       "8   ( when she thought it over afterwards , it occ...   \n",
       "9   In another moment down went Alice after it , n...   \n",
       "10  The rabbit - hole went straight on like a tunn...   \n",
       "11  Either the well was very deep , or she fell ve...   \n",
       "12  First , she tried to look down and make out wh...   \n",
       "13  She took down a jar from one of the shelves as...   \n",
       "14                                          ' Well !'   \n",
       "15  thought Alice to herself , ' after such a fall...   \n",
       "16         How brave they ' ll all think me at home !   \n",
       "17  Why , I wouldn ' t say anything about it , eve...   \n",
       "18                    ( Which was very likely true .)   \n",
       "19                               Down , down , down .   \n",
       "\n",
       "                                            Sents_pos  \\\n",
       "0   [/JJ Alice/NNP '/POS s/NN Adventures/NNS in/IN...   \n",
       "1                                CHAPTER/NN I/PRP ./.   \n",
       "2               Down/IN the/DT Rabbit/NNP -/: Hole/NN   \n",
       "3   Alice/NNP was/VBD beginning/VBG to/TO get/VB v...   \n",
       "4   So/IN she/PRP was/VBD considering/VBG in/IN he...   \n",
       "5   There/EX was/VBD nothing/NN so/RB VERY/RB rema...   \n",
       "6                                   Oh/UH dear/NN !/.   \n",
       "7                  I/PRP shall/MD be/VB late/JJ !'/NN   \n",
       "8   (/( when/WRB she/PRP thought/VBD it/PRP over/I...   \n",
       "9   In/IN another/DT moment/NN down/RP went/VBD Al...   \n",
       "10  The/DT rabbit/NN -/: hole/NN went/VBD straight...   \n",
       "11  Either/CC the/DT well/NN was/VBD very/RB deep/...   \n",
       "12  First/RB ,/, she/PRP tried/VBD to/TO look/VB d...   \n",
       "13  She/PRP took/VBD down/RP a/DT jar/NN from/IN o...   \n",
       "14                               '/POS Well/NNP !'/NN   \n",
       "15  thought/VBN Alice/NNP to/TO herself/VB ,/, '/'...   \n",
       "16  How/WRB brave/VBP they/PRP '/'' ll/VBP all/DT ...   \n",
       "17  Why/WRB ,/, I/PRP wouldn/VBP '/'' t/NNS say/VB...   \n",
       "18  (/( Which/NNP was/VBD very/RB likely/JJ true/J...   \n",
       "19               Down/NNP ,/, down/RB ,/, down/RB ./.   \n",
       "\n",
       "                                            Sents_lem  \n",
       "0   [ Alice ' s Adventures in Wonderland by Lewis ...  \n",
       "1                                         CHAPTER I .  \n",
       "2                              Down the Rabbit - Hole  \n",
       "3   Alice be begin to get very tired of sit by her...  \n",
       "4   So she be consider in her own mind ( as well a...  \n",
       "5   There be nothing so VERY remarkable in that ; ...  \n",
       "6                                           Oh dear !  \n",
       "7                                  I shall be late !'  \n",
       "8   ( when she think it over afterwards , it occur...  \n",
       "9   In another moment down go Alice after it , nev...  \n",
       "10  The rabbit - hole go straight on like a tunnel...  \n",
       "11  Either the well be very deep , or she fell ver...  \n",
       "12  First , she try to look down and make out what...  \n",
       "13  She take down a jar from one of the shelf a sh...  \n",
       "14                                          ' Well !'  \n",
       "15  think Alice to herself , ' after such a fall a...  \n",
       "16         How brave they ' ll all think me at home !  \n",
       "17  Why , I wouldn ' t say anything about it , eve...  \n",
       "18                     ( Which be very likely true .)  \n",
       "19                               Down , down , down .  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alice_sents_df = pd.DataFrame({'Sents': sents, 'Sents_pos': sents_pos, 'Sents_lem': sents_lem})\n",
    "alice_sents_df[:20]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Question 2\n",
    "Based on the output of Question 1, please create a lemma frequency list of the corpus, carroll-alice.txt, using the lemmatized forms by including only lemmas which are:\n",
    "\n",
    "consisting of only alphabets or hyphens\n",
    "    - at least 5-character long\n",
    "    - The casing is irrelevant (i.e., case normalization is needed).\n",
    "\n",
    "The expected output is provided as follows (showing the top 20 lemmas and their frequencies)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'bb', 'ccc', 'd', 'ee']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sth new w/ nest list and for loop\n",
    "list = [[\"a\", \"bb\", \"ccc\"], [\"d\", \"ee\"]]\n",
    "\n",
    "[item1 for s in list for item1 in s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['a', 'bb', 'ccc'], ['d', 'ee']]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sth new w/ nest list and for loop\n",
    "[[item2 for item2 in s] for s in list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[', 'Alice', \"'\", 's', 'Adventures', 'in', 'Wonderland', 'by', 'Lewis', 'Carroll']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "#lemmatize all the sents\n",
    "all_lemma = [wnl.lemmatize(pair[0], pos = get_wordnet_pos(pair[1])) for s in text_pos for pair in s]\n",
    "print(all_lemma[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alice', 'adventures', 'wonderland', 'lewis', 'carroll', 'chapter', 'rabbit', 'alice', 'begin', 'tired', 'sister', 'nothing', 'twice', 'sister', 'picture', 'conversation', 'think', 'alice', 'without', 'picture']\n"
     ]
    }
   ],
   "source": [
    "#filtered out the lemma we need\n",
    "regex = re.compile('[-a-z]{5,}')\n",
    "filtered_lemma = [i.lower() for i in all_lemma if regex.match(i.lower())]\n",
    "print(filtered_lemma[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alice': 3,\n",
       " 'adventures': 1,\n",
       " 'wonderland': 1,\n",
       " 'lewis': 1,\n",
       " 'carroll': 1,\n",
       " 'chapter': 1,\n",
       " 'rabbit': 1,\n",
       " 'begin': 1,\n",
       " 'tired': 1,\n",
       " 'sister': 2,\n",
       " 'nothing': 1,\n",
       " 'twice': 1,\n",
       " 'picture': 2,\n",
       " 'conversation': 1,\n",
       " 'think': 1,\n",
       " 'without': 1}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def CountFrequency(list):\n",
    "      \n",
    "   # Creating an empty dictionary \n",
    "    count = {}\n",
    "    for i in list:\n",
    "        count[i] = count.get(i, 0) + 1\n",
    "    return count\n",
    "    \n",
    "CountFrequency(filtered_lemma[:20])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('alice', 398), ('little', 128), ('think', 118)]\n"
     ]
    }
   ],
   "source": [
    "sortedLemma = sorted(CountFrequency(filtered_lemma).items(), key = lambda ex: ex[1], reverse = True)\n",
    "print(sortedLemma[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LEMMA</th>\n",
       "      <th>FREQ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alice</td>\n",
       "      <td>398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>little</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>think</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>there</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>about</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>begin</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>would</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>again</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>herself</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>thing</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>could</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>queen</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>turtle</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>hatter</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>quite</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>gryphon</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>rabbit</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>their</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>first</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>voice</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>which</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      LEMMA  FREQ\n",
       "0     alice   398\n",
       "1    little   128\n",
       "2     think   118\n",
       "3     there    99\n",
       "4     about    94\n",
       "5     begin    92\n",
       "6     would    83\n",
       "7     again    83\n",
       "8   herself    83\n",
       "9     thing    80\n",
       "10    could    77\n",
       "11    queen    75\n",
       "12   turtle    61\n",
       "13   hatter    57\n",
       "14    quite    55\n",
       "15  gryphon    55\n",
       "16   rabbit    52\n",
       "17    their    52\n",
       "18    first    51\n",
       "19    voice    51\n",
       "20    which    49"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "alice_df = pd.DataFrame(sortedLemma, columns = ['LEMMA', 'FREQ'])\n",
    "alice_df[:21]\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Question 3\n",
    "Please identify top verbs that co-occcur with the name Alice in the text, with Alice being the subject of the verb.\n",
    "\n",
    "Please use the en_core_web-sm model in spacy for English dependency parsing.\n",
    "\n",
    "To simply the task, please identify all the verbs that have a dependency relation of nsubj with the noun Alice (where Alice is the dependent, and the verb is the head).\n",
    "\n",
    "The expected output is provided below (showing the top 20 heads of Alice for the nsubj dependency relation.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy.download(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "# load language model\n",
    "nlp_en = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nlp_en' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-0a0c462f9dde>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmeta_sents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnlp_en\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"Alice\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdep_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"nsubj\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msents\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeta_sents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-30-0a0c462f9dde>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmeta_sents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnlp_en\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"Alice\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdep_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"nsubj\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msents\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeta_sents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nlp_en' is not defined"
     ]
    }
   ],
   "source": [
    "meta_sents = [[token for token in nlp_en(s) if token.text == \"Alice\" and token.dep_ == \"nsubj\"] for s in sents]\n",
    "print(meta_sents[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsubj_head = [token.head.text for lst in meta_sent for token in lst]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
